{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eae2566-1099-4c74-9840-0d3790ae2cb6",
   "metadata": {},
   "source": [
    "## **Deep Learning Credit Scoring with TensorFlow**\n",
    "\n",
    "This project is divided into two parts. In the first part, I will explore **TensorFlow**, a deep learning framework, to build my own **Neural Networks** from scratch. In the second part, I will apply the skills acquired in the first part to **develop and train a neural network** that predicts a person's **credit score**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bfd86-9409-4ca3-bcf2-da6fc0ffc84f",
   "metadata": {},
   "source": [
    "This project aims to build a strong foundation in TensorFlow by learning essential deep learning techniques, including variable initialization, session management, and algorithm training, which are crucial for developing and optimizing neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ceb56-863c-4df5-a9d2-3b7129844fa5",
   "metadata": {},
   "source": [
    "**What is TensorFlow?**\n",
    "TensorFlow is an open-source deep learning framework developed by Google. It helps build, train, and deploy machine learning (ML) and deep learning models efficiently. It supports both CPU and GPU processing, making it scalable for small and large projects.\n",
    "\n",
    "**Why is TensorFlow Important for Data Analytics?**\n",
    "- Predictive Analytics – Helps analyze trends and make forecasts using deep learning.\n",
    "- Automated Insights – Can detect patterns in data that traditional analytics might miss.\n",
    "- Scalability – Handles large datasets efficiently, useful for big data analysis.\n",
    "- Integration – Works with tools like Python, SQL, and Power BI to enhance analytical workflows.\n",
    "  \n",
    "*Note: TensorFlow can be valuable for advanced analytics, forecasting, and automation, making you a more competitive analyst.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc2d8d-4c6f-4d6c-b4f8-71eead166494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbee5e-fdc2-4863-b68d-15614068250e",
   "metadata": {},
   "source": [
    "Now that I have imported the library, I will explore its various applications. I will begin with an example by computing the squared error loss.\n",
    "\n",
    "$$\n",
    "\\text{loss} = \\mathcal{L}(\\hat{y}, y) = (\\hat{y}^{(i)} - y^{(i)})^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb958eb4-c923-4558-a6aa-320f17220a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_38492\\217878198.py:4: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable Eager Execution (for TensorFlow 1.x behavior)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define y_hat and y\n",
    "y_hat = tf.constant(36, name='y_hat')\n",
    "y = tf.constant(39, name='y')\n",
    "\n",
    "# Define the loss variable\n",
    "loss = tf.Variable((y - y_hat) ** 2, name='loss')\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Create a session and run the computation\n",
    "with tf.compat.v1.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097177b-a914-4e4e-b448-af8c67f5cdde",
   "metadata": {},
   "source": [
    "\n",
    "- Create Tensors (variables): Define the tensors without immediately executing or evaluating them.\n",
    "- Define operations: Specify mathematical operations between the tensors.\n",
    "- Initialize the tensors: Prepare the tensors for computation.\n",
    "- Create a session: Establish a session to manage execution.\n",
    "- Run the session: Execute the defined operations within the session.\n",
    "                                             \n",
    "*When I created a variable for the loss, I defined it as a function of other quantities without evaluating its value. To compute it, I initialized the variable using init = tf.global_variables_initializer(). This step ensured that the loss variable was properly set up, allowing me to evaluate and print its value in the final step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5957bec-1312-4b13-b6fb-9b1262d8503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ada138a-5616-4543-b627-5052e421eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable Eager Execution (Make TensorFlow 2.x behave like TensorFlow 1.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define constants\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "\n",
    "# Perform multiplication\n",
    "c = tf.multiply(a, b)\n",
    "\n",
    "# Create a Session (Using TF 1.x style)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a0ade-a70a-4841-ae54-e8fd7ab252a1",
   "metadata": {},
   "source": [
    "To summarize, always remember to initialize your variables, create a session, and execute operations within the session.\n",
    "\n",
    "Next, it's important to understand placeholders. A placeholder is a tensor whose value is assigned later during execution. To provide a value for a placeholder, you use a feed dictionary (feed_dict). In the example below, we define a placeholder for x, allowing us to specify its value dynamically when running the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62b0d98-2844-4bc4-ab3d-f4d3fbedc024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable Eager Execution (Make TensorFlow 2.x behave like TensorFlow 1.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define a placeholder (TF 1.x style)\n",
    "x = tf.compat.v1.placeholder(tf.int64, name='x')\n",
    "\n",
    "# Create a session and run computation\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(2 * x, feed_dict={x: 3}))  # Output: 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7905d2-3385-479f-b1e8-6a21f46c7c7e",
   "metadata": {},
   "source": [
    "A placeholder is a variable that receives its value later, during session execution. This process is known as feeding data into placeholders at runtime.\n",
    "\n",
    "**Analysis:**\n",
    "When defining operations in TensorFlow, I am constructing a computation graph, which represents the sequence of calculations. This graph may include placeholders, whose values are assigned dynamically during execution. When the session runs, TensorFlow processes the computation graph and evaluates the necessary operations using the provided data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec68b46-c605-44cc-8db0-ade9a9d6746a",
   "metadata": {},
   "source": [
    "### **1.0 Logit Calculation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3dcb4-b65b-4755-a463-98ae05d67a6c",
   "metadata": {},
   "source": [
    "I started this exercise by computing the following equation:  \n",
    "\n",
    "$ Y = \\mathbf{W} \\mathbf{X} + \\mathbf{b} $  \n",
    "\n",
    "where **$\\mathbf{W}$** and **$\\mathbf{X}$** are random matrices, and **$\\mathbf{b}$** is a random vector.  \n",
    "\n",
    "Below are examples of the functions I needing, to complete this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50328637-9a64-4a29-9b1f-d233de23ef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.62434536, -0.61175641, -0.52817175, -1.07296862])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random vector\n",
    "np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e41fbba-ae14-4585-88b1-ebc5e149125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86540763, -2.3015387 ,  1.74481176],\n",
       "       [-0.7612069 ,  0.3190391 , -0.24937038]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Matrix\n",
    "np.random.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f39443a-7060-4954-aa24-e6f66165c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Addition with tensorflow\n",
    "x1 = tf.constant(5, name=\"x1\")\n",
    "x2 = tf.constant(15, name=\"x2\")\n",
    "operation = tf.add(x1,x2)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(operation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b0e6cd-5dc3-45f0-93ed-055c3f79b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication: Shapes (2,1), (1,2)\n",
    "x1 = tf.constant([[2],[1]], name=\"x1\")\n",
    "x2 = tf.constant([[2,1]], name=\"x2\")\n",
    "operation = tf.matmul(x1,x2)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(operation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077d302-023b-4b6a-810f-2b2668aef477",
   "metadata": {},
   "source": [
    "#### **Exercise 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a4c0e-06a8-4f4c-97b3-f5bfdd5b960d",
   "metadata": {},
   "source": [
    "Compute $ W X + b $ where **$ W $**, **$ X $**, and **$ b $** are drawn from a random normal distribution.  \n",
    "$ W $ has a shape of **(4,3)**, $ X $ is **(3,1)**, and $ b $ is **(4,1)**.  \n",
    "\n",
    "As an example, here is how you would define a constant $ X $ with shape **(3,1)**:\n",
    "\n",
    "```python\n",
    "X = tf.constant(np.random.randn(3,1), name=\"X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67c9747-cfdd-4697-8437-56a0bea50ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = \n",
      " [[-1.98748544]\n",
      " [-2.76826248]\n",
      " [-0.78635415]\n",
      " [-2.77463846]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Disable Eager Execution (Make TensorFlow 2.x behave like TensorFlow 1.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define the function to compute logits\n",
    "def compute_logits():\n",
    "    \"\"\"\n",
    "    Implements a linear function: Y = WX + b\n",
    "    - Initializes W as a random tensor of shape (4,3)\n",
    "    - Initializes X as a random tensor of shape (3,1)\n",
    "    - Initializes b as a random tensor of shape (4,1)\n",
    "    Returns:\n",
    "    - result: Computed value of Y = WX + b\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)  # Set seed for reproducibility\n",
    "\n",
    "    # Define random tensors\n",
    "    W = tf.constant(np.random.randn(4,3), name=\"W\")\n",
    "    X = tf.constant(np.random.randn(3,1), name=\"X\")\n",
    "    b = tf.constant(np.random.randn(4,1), name=\"b\")\n",
    "\n",
    "    # Compute Y = WX + b\n",
    "    result = tf.add(tf.matmul(W, X), b)\n",
    "\n",
    "    # Create a session and run the computation\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())  # Initialize variables\n",
    "        return sess.run(result)\n",
    "\n",
    "# Run function and print result\n",
    "print(\"result = \\n\", compute_logits())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad8c70-52d2-46ea-ba9b-9ee32ad7d642",
   "metadata": {},
   "source": [
    "### **1.1 Computing the sigmoid function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3061748-e434-48f6-bc6b-79e2a94d314e",
   "metadata": {},
   "source": [
    "I just implemented a linear function. TensorFlow offers a variety of commonly used neural network functions like `tf.sigmoid` and `tf.nn.relu`. For this exercise, I will compute the sigmoid function of an input.\n",
    "\n",
    "In this exercise:\n",
    "1. **Create a placeholder** $ x $.\n",
    "2. **Define the operations** needed to compute the sigmoid using `tf.sigmoid`.\n",
    "3. **Run the session**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Exercise 2.**\n",
    "**Implement the Sigmoid Function**\n",
    "You should use the following:\n",
    "- `tf.placeholder(tf.float32, name = \"...\")`\n",
    "- `tf.sigmoid(...)`\n",
    "- `sess.run(..., feed_dict = {x: z})`\n",
    "\n",
    "---\n",
    "\n",
    "**TensorFlow Session Methods**\n",
    "There are two typical ways to create and use sessions in TensorFlow:\n",
    "\n",
    "**Method 1**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# Run the variables initialization (if needed), run the operations\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() # Close the session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338c22d-a4de-4cbd-b3e8-8ed0e46c8f27",
   "metadata": {},
   "source": [
    "**Method 2**\n",
    "```python \n",
    "with tf.Session() as sess:\n",
    "    # Run the variables initialization (if needed), run the operations\n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # This takes care of closing the session for you :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e359db78-3394-45f9-a383-7789efc528a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ebf5d8-1f54-4e30-ad90-6ae083f2d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    \n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name=\"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. Please use the method 2 explained above. \n",
    "    # You should use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as sess:\n",
    "        # Run session and call the output \"result\"\n",
    "        result = sess.run(sigmoid, feed_dict={x:z})\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a82829f7-e696-44c7-9f40-ee89e4c22fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = Tensor(\"Sigmoid_1:0\", shape=(), dtype=float32)\n",
      "sigmoid(12) = Tensor(\"Sigmoid_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22650edd-18c8-4c8e-8244-96ba95c73661",
   "metadata": {},
   "source": [
    "### **1.2 Computing the Cost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08463ca-b60f-4749-818f-7095ef4eb794",
   "metadata": {},
   "source": [
    "#### **Exercise 3.**\n",
    "**Implement the Mean Squared Loss**\n",
    "The **mean squared loss (MSE)** is the loss function used in **regression problems**. Your task is to compute the cost of the **Mean Squared Error (MSE)**.\n",
    "\n",
    "The function you will use is:\n",
    "\n",
    "```python\n",
    "tf.reduce_mean(tf.square(prediction - label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9315a21a-cd86-47a8-af27-d211f14a1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Disable Eager Execution (Make TensorFlow 2.x behave like TensorFlow 1.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def cost():\n",
    "    \"\"\"\n",
    "    Computes the cost using MSE (Mean Squared Error)\n",
    "    \"\"\"\n",
    "    # Define placeholders (TF 1.x style)\n",
    "    z = tf.compat.v1.placeholder(tf.float32, name=\"z\")\n",
    "    y = tf.compat.v1.placeholder(tf.float32, name=\"y\")\n",
    "\n",
    "    # Compute MSE\n",
    "    loss = tf.reduce_mean(tf.square(z - y))\n",
    "\n",
    "    # Create session\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        result = sess.run(loss, feed_dict={z: np.array([4.0, 3.0, 3.5]), \n",
    "                                           y: np.array([7.0, 6.0, 0.5])})\n",
    "        return result\n",
    "\n",
    "# Run function\n",
    "print(\"cost =\", cost())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a856ae-49d7-49eb-a9cc-379d5a9620c4",
   "metadata": {},
   "source": [
    "### **1.3 Initialize with zeros and ones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9dca13-96ce-47cd-b3a2-619077b5152d",
   "metadata": {},
   "source": [
    "Now, I will learn how to initialize vectors filled with zeros and ones. The function **`tf.ones()`** creates an array filled with ones, while **`tf.zeros()`** initializes an array of the same shape filled with zeros. Both functions require a shape parameter and return an array with the specified dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10cbda-ede5-4cac-aaec-e893980fb6f6",
   "metadata": {},
   "source": [
    "#### **Exercise 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580b175-f39f-4d4a-af65-ff9f020baf63",
   "metadata": {},
   "source": [
    " Implement the function below to take in a shape and to return an array (of the shape's dimension of ones).\n",
    "\n",
    "**`tf.ones(shape)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8e4db0-5d16-486a-a8b1-c32e5e807dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b0083f1-3255-4e87-add2-82307dc1b2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones =  Tensor(\"ones:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of ones of dimension shape.\n",
    "    \"\"\"\n",
    "    ones_tensor = tf.ones(shape)\n",
    "    return ones_tensor\n",
    "\n",
    "# Print the result directly (TensorFlow 2.x supports eager execution by default)\n",
    "print(\"ones = \", ones([3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4dc1e8-204a-4d32-87df-e164d7b8349a",
   "metadata": {},
   "source": [
    "### **2.0 Credit Scoring Section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe090d3a-0921-44ac-883a-aedcc18974c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/german-credit?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 10.9k/10.9k [00:00<00:00, 7.57MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\jorda\\.cache\\kagglehub\\datasets\\uciml\\german-credit\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/german-credit\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98447e76-24fc-49ac-ad85-bdbeed1340b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "   Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
      "0           0   67    male    2     own             NaN           little   \n",
      "1           1   22  female    2     own          little         moderate   \n",
      "2           2   49    male    1     own          little              NaN   \n",
      "3           3   45    male    2    free          little           little   \n",
      "4           4   53    male    2    free          little           little   \n",
      "\n",
      "   Credit amount  Duration              Purpose  \n",
      "0           1169         6             radio/TV  \n",
      "1           5951        48             radio/TV  \n",
      "2           2096        12            education  \n",
      "3           7882        42  furniture/equipment  \n",
      "4           4870        24                  car  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the correct file path using the file name only\n",
    "train_path = 'german_credit_data.csv'\n",
    "\n",
    "# Load the dataset\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Train Data:\")\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02db4c2c-2c8b-4288-be5a-1542549b2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the dataset:\n",
      "Unnamed: 0            0\n",
      "Age                   0\n",
      "Sex                   0\n",
      "Job                   0\n",
      "Housing               0\n",
      "Saving accounts     183\n",
      "Checking account    394\n",
      "Credit amount         0\n",
      "Duration              0\n",
      "Purpose               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "print(train.isnull().sum())\n",
    "\n",
    "# Check the distribution of the target variable (if exists)\n",
    "if \"ProbabilityOfDefaultIn2Yrs\" in train.columns:\n",
    "    print(\"\\nTarget distribution:\")\n",
    "    print(train[\"ProbabilityOfDefaultIn2Yrs\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a372f2b-8a41-42ea-a19f-f62588662342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['Unnamed: 0', 'Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n",
      "       'Checking account', 'Credit amount', 'Duration', 'Purpose'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names to check for typos or different column names\n",
    "print(\"Columns in the dataset:\")\n",
    "print(train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d167d755-113c-4dc4-8b73-9cffc6cb525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables using label encoding or one-hot encoding\n",
    "train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})  # Example mapping\n",
    "\n",
    "# For other categorical columns, you could use pd.get_dummies for one-hot encoding\n",
    "train = pd.get_dummies(train, columns=['Job', 'Housing', 'Saving accounts', 'Checking account'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68a36708-1892-4b56-84b6-65506752925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Unnamed: 0' column as it is just an index\n",
    "train = train.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Now, let's assume 'Purpose' is the target column and the rest are features\n",
    "x_train = train.drop(\"Purpose\", axis=1)  # Features\n",
    "y_train = train[\"Purpose\"]  # Target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35a1a278-806a-4b2f-bcfb-365e7d8d2e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age  Sex  Credit amount  Duration              Purpose  Job_1  Job_2  \\\n",
      "0  2.766456  NaN      -0.745131 -1.236478             radio/TV  False   True   \n",
      "1 -1.191404  NaN       0.949817  2.248194             radio/TV  False   True   \n",
      "2  1.183312  NaN      -0.416562 -0.738668            education   True  False   \n",
      "3  0.831502  NaN       1.634247  1.750384  furniture/equipment  False   True   \n",
      "4  1.535122  NaN       0.566664  0.256953                  car  False   True   \n",
      "\n",
      "   Job_3  Housing_own  Housing_rent  Saving accounts_moderate  \\\n",
      "0  False         True         False                     False   \n",
      "1  False         True         False                     False   \n",
      "2  False         True         False                     False   \n",
      "3  False        False         False                     False   \n",
      "4  False        False         False                     False   \n",
      "\n",
      "   Saving accounts_quite rich  Saving accounts_rich  \\\n",
      "0                       False                 False   \n",
      "1                       False                 False   \n",
      "2                       False                 False   \n",
      "3                       False                 False   \n",
      "4                       False                 False   \n",
      "\n",
      "   Checking account_moderate  Checking account_rich  \n",
      "0                      False                  False  \n",
      "1                       True                  False  \n",
      "2                      False                  False  \n",
      "3                      False                  False  \n",
      "4                      False                  False  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale numerical features (e.g., 'Age', 'Credit amount', 'Duration')\n",
    "numerical_features = ['Age', 'Credit amount', 'Duration']\n",
    "scaler = StandardScaler()\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "\n",
    "# Check the scaled data\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6904de4d-d6ee-46b7-a38d-c5d626771ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           business       0.00      0.00      0.00        18\n",
      "                car       0.33      0.68      0.44        63\n",
      "domestic appliances       0.00      0.00      0.00         1\n",
      "          education       0.00      0.00      0.00        15\n",
      "furniture/equipment       0.00      0.00      0.00        44\n",
      "           radio/TV       0.42      0.54      0.47        54\n",
      "            repairs       0.00      0.00      0.00         3\n",
      "    vacation/others       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.36       200\n",
      "          macro avg       0.09      0.15      0.11       200\n",
      "       weighted avg       0.22      0.36      0.27       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jorda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jorda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jorda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2af3c1fb-4e0b-4e79-adb1-0ae0b4de88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1000, 14)\n",
      "y_train shape: (800,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of x_train and y_train to ensure they match\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e525f31f-c18e-4bcd-9217-a55a83d1066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of rows in the dataset\n",
    "print(f\"Total number of rows in the dataset: {train.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e7daf4e-6395-450e-820f-f8e1a037ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1000, 14)\n",
      "y_train shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Define the target variable (y_train) and features (x_train) correctly\n",
    "y_train = train[\"Purpose\"]  # Target column\n",
    "x_train = train.drop(\"Purpose\", axis=1)  # Drop target column to get features\n",
    "\n",
    "# Verify their shapes match\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "966cf13c-e9ab-490c-bed7-b6eb41c83987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 14)\n",
      "X_test shape: (200, 14)\n",
      "y_train shape: (800,)\n",
      "y_test shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shape of the split data\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1859fb1-471f-40f5-af5b-ef1f09d197f2",
   "metadata": {},
   "source": [
    "### **2.1 Create placeholders**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59922881-1ab9-4c79-96cc-50bda3c72074",
   "metadata": {},
   "source": [
    "The first task is to create placeholders for X and Y. This will allow you to later pass your training data in when you run your session.\n",
    "\n",
    "#### **Exercise 5.** \n",
    "Implement the function below to create the placeholders in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90280130-7dfe-472b-a3ad-bb07ddda289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded target values: [0 3 1 1 5 1 4 4 4 4 6 5 1 0 1 3 3 5 3 5 4 1 5 5 5 3 1 2 5 1 1 1 1 4 0 4 1\n",
      " 5 0 1 4 1 1 1 1 0 0 5 5 1 0 5 3 5 1 4 5 1 5 3 5 1 0 0 5 0 1 4 4 1 5 4 1 1\n",
      " 1 1 5 4 5 1 4 4 5 0 5 5 4 6 4 0 4 1 1 0 1 0 5 4 1 4 1 1 4 1 1 5 4 5 5 5 7\n",
      " 3 1 4 4 1 5 1 0 0 4 4 1 4 5 1 5 1 3 4 0 4 1 3 5 4 1 5 0 1 5 1 4 1 4 1 5 5\n",
      " 5 1 0 6 1 5 1 3 1 4 4 4 4 1 5 1 1 5 5 5 0 5 0 1 1 5 4 0 0 0 5 2 5 0 4 5 5\n",
      " 1 1 4 3 1 5 5 5 4 2 5 5 7 5 5 4 5 4 1 4 5 4 4 1 1 1 4 1 1 5 5 5 0 1 5 1 1\n",
      " 4 5 6 4 7 5 5 1 1 3 3 1 4 5 1 4 1 0 0 1 6 1 1 4 4 4 7 1 4 2 5 1 4 1 3 5 0\n",
      " 0 3 1 1 1 1 1 5 3 1 1 1 5 4 6 5 1 5 5 4 1 1 1 0 4 5 1 6 5 4 4 5 0 1 1 5 5\n",
      " 4 1 4 1 3 5 3 4 4 5 0 1 5 1 5 1 4 5 1 1 5 1 1 1 5 4 0 3 7 5 5 3 5 4 4 3 0\n",
      " 1 4 4 1 1 5 1 5 4 1 1 4 1 0 1 1 5 5 3 1 5 4 5 4 1 5 3 3 1 5 1 3 3 5 1 4 5\n",
      " 5 4 5 4 5 1 5 5 5 5 1 5 1 0 1 5 4 0 2 1 0 1 0 6 1 0 7 3 5 4 0 6 1 5 5 6 0\n",
      " 5 5 0 0 5 1 1 5 1 1 4 4 1 1 3 1 4 5 1 1 1 1 1 1 5 4 5 5 6 5 1 1 0 4 4 5 5\n",
      " 7 1 5 1 0 1 5 1 4 5 1 0 3 5 2 1 5 5 4 1 3 5 5 4 1 1 4 1 5 1 1 1 5 1 1 2 0\n",
      " 0 5 5 5 3 4 4 4 1 1 5 4 5 5 1 2 1 1 5 3 3 1 6 0 1 1 1 5 5 0 4 0 3 1 1 1 1\n",
      " 5 4 1 4 1 5 1 5 4 4 0 6 5 1 1 5 1 1 0 1 5 0 1 1 2 0 1 6 7 0 5 4 5 4 1 5 1\n",
      " 1 5 5 4 4 1 6 5 4 5 0 1 0 6 5 0 4 4 1 5 4 5 5 1 4 1 5 5 5 0 1 4 1 1 5 1 5\n",
      " 5 5 5 1 1 5 0 1 1 5 3 4 0 1 5 5 5 5 5 1 1 0 4 1 4 1 0 1 1 5 5 4 4 1 1 4 1\n",
      " 4 4 4 5 5 1 4 3 1 5 1 1 1 5 5 1 5 0 1 5 1 1 6 5 3 5 5 1 5 1 1 1 5 1 0 4 0\n",
      " 5 5 0 3 1 1 5 6 1 1 5 1 1 6 5 5 1 1 1 0 1 5 1 2 1 1 1 4 1 4 5 1 1 1 1 5 5\n",
      " 1 1 5 0 0 5 1 5 3 7 5 0 5 5 1 5 5 1 4 1 5 5 1 1 1 4 4 0 5 1 5 1 4 5 4 5 4\n",
      " 4 5 4 7 1 4 1 1 0 1 1 5 5 4 3 3 4 5 1 1 5 1 3 1 1 5 1 5 5 5 5 0 5 1 1 0 0\n",
      " 5 4 1 1 4 1 1 4 3 2 1 5 5 1 4 1 4 5 1 1 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Check the transformed target values\n",
    "print(\"Encoded target values:\", y_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc6f1678-64ce-467b-93d8-96b95918ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor: Tensor(\"Const_5:0\", shape=(800, 14), dtype=float32)\n",
      "Y_tensor: Tensor(\"Const_6:0\", shape=(800, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert the features and target into TensorFlow tensors\n",
    "X_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "Y_tensor = tf.convert_to_tensor(y_train_encoded.reshape(-1, 1), dtype=tf.float32)\n",
    "\n",
    "# Verify the tensors\n",
    "print(\"X_tensor:\", X_tensor)\n",
    "print(\"Y_tensor:\", Y_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2527736-39d8-41e1-a709-0cea2f08f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W, b):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for logistic regression.\n",
    "    Z -- linear step\n",
    "    A -- sigmoid activation function\n",
    "    \"\"\"\n",
    "    # Transpose X to match the dimensions for matrix multiplication\n",
    "    X = tf.transpose(X)  # Transpose the feature matrix to shape (14, 800)\n",
    "\n",
    "    Z = tf.add(tf.matmul(W, X), b)  # Linear step: (14, 1) * (14, 800)\n",
    "    A = tf.sigmoid(Z)  # Sigmoid activation function\n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3925f997-55b4-455a-8cfa-cf1452c1282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "Age                 0\n",
      "Sex                 0\n",
      "Job                 0\n",
      "Housing             0\n",
      "Saving accounts     0\n",
      "Checking account    0\n",
      "Credit amount       0\n",
      "Duration            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_38492\\366615799.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns  # Only select numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns  # Categorical columns (string)\n",
    "\n",
    "# Fill missing values for numerical columns with the mean\n",
    "X[numerical_features] = X[numerical_features].fillna(X[numerical_features].mean())\n",
    "\n",
    "# For categorical columns, fill missing values with the mode (most frequent value)\n",
    "for col in categorical_features:\n",
    "    X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(X.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59a9e0-9398-42d0-80dd-f0d83bdcaeb9",
   "metadata": {},
   "source": [
    "### **2.2 Initializing the parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45962d38-4255-43ba-ac4b-99cc12e03f30",
   "metadata": {},
   "source": [
    "The second task is to initialize the parameters in TensorFlow. \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119098e5-8187-434e-81c3-158906e9dd64",
   "metadata": {},
   "source": [
    "input (10 * 1) -> layer 1 (5 neurons, relu) -> layer 2 (10 neurons, relu) -> layer 3 (1 neuron, sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555250e-da5b-4d14-929d-b3220a363e91",
   "metadata": {},
   "source": [
    "#### **Exercise 6.**\n",
    "\n",
    "Implement the function below to initialize the parameters in TensorFlow. You are going to use Xavier Initialization for weights and Zero Initialization for biases. The shapes are given below. As an example, to help you, for `W1` and `b1` you could use:\n",
    "\n",
    "```python\n",
    "W1 = tf.get_variable(\"W1\", [5,10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [5,1], initializer = tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0cc0a-52a0-45d4-9793-12f039bab8a0",
   "metadata": {},
   "source": [
    "*For W1, we have 5 neurons, each having 10 weight values (because we have 10 inputs at layer 1). For b1, we have the same 5 neurons with 1 bias value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8972e8d8-91ef-4d1e-a9b6-b6256cc04298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GRADED FUNCTION: initialize_parameters\n",
    "def initialize_parameters(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with TensorFlow. The shapes are:\n",
    "                        W1 : [5, n_x]    --> 5 neurons in the first hidden layer\n",
    "                        b1 : [5, 1]      --> 5 bias terms for the first hidden layer\n",
    "                        W2 : [10, 5]     --> 10 neurons in the second hidden layer\n",
    "                        b2 : [10, 1]     --> 10 bias terms for the second hidden layer\n",
    "                        W3 : [1, 10]     --> 1 output neuron for binary classification\n",
    "                        b3 : [1, 1]      --> 1 bias term for the output layer\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, dimension of the input (number of features)\n",
    "    n_y -- scalar, dimension of the output (1 for binary classification)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_seed(1)  # so that your \"random\" numbers match ours\n",
    "\n",
    "    # Initialize parameters\n",
    "    W1 = tf.Variable(tf.keras.initializers.GlorotUniform(seed=1)(shape=[5, n_x]), name=\"W1\")\n",
    "    b1 = tf.Variable(tf.zeros_initializer()(shape=[5, 1]), name=\"b1\")\n",
    "    W2 = tf.Variable(tf.keras.initializers.GlorotUniform(seed=1)(shape=[10, 5]), name=\"W2\")\n",
    "    b2 = tf.Variable(tf.zeros_initializer()(shape=[10, 1]), name=\"b2\")\n",
    "    W3 = tf.Variable(tf.keras.initializers.GlorotUniform(seed=1)(shape=[1, 10]), name=\"W3\")\n",
    "    b3 = tf.Variable(tf.zeros_initializer()(shape=[1, 1]), name=\"b3\")\n",
    "\n",
    "    # Store all parameters in a dictionary\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "\n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd254bf0-ed03-46a0-a935-2d79514dea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: <tf.Variable 'W1:0' shape=(5, 14) dtype=float32>\n",
      "b1: <tf.Variable 'b1:0' shape=(5, 1) dtype=float32>\n",
      "W2: <tf.Variable 'W2:0' shape=(10, 5) dtype=float32>\n",
      "b2: <tf.Variable 'b2:0' shape=(10, 1) dtype=float32>\n",
      "W3: <tf.Variable 'W3:0' shape=(1, 10) dtype=float32>\n",
      "b3: <tf.Variable 'b3:0' shape=(1, 1) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your dataset\n",
    "n_x = X_train.shape[1]  # 14 features in the input data\n",
    "n_y = 1  # Binary output\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = initialize_parameters(n_x, n_y)\n",
    "\n",
    "# Print initialized parameters\n",
    "print(\"W1:\", parameters[\"W1\"])\n",
    "print(\"b1:\", parameters[\"b1\"])\n",
    "print(\"W2:\", parameters[\"W2\"])\n",
    "print(\"b2:\", parameters[\"b2\"])\n",
    "print(\"W3:\", parameters[\"W3\"])\n",
    "print(\"b3:\", parameters[\"b3\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234547e9-542f-4af5-a271-665e0cb06611",
   "metadata": {},
   "source": [
    "### **2.3 Forward propagation in tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeae118-eb82-40dc-9621-1cbd82323902",
   "metadata": {},
   "source": [
    "I will now implement the forward propagation module in TensorFlow. The function will take in a dictionary of parameters and it will complete the forward pass. The functions I used are:\n",
    "\n",
    "- `tf.add(...)` to do an addition\n",
    "- `tf.matmul(...)` to do a matrix multiplication\n",
    "- `tf.nn.relu(...)` to apply the ReLU activation\n",
    "\n",
    "#### **Question 7.**\n",
    "\n",
    "Implement the forward pass of the neural network. I commented the numpy equivalents so that you can compare the tensorflow implementation to numpy. It is important to note that the forward propagation stops at `z3`. The reason is that in tensorflow the last linear layer output is given as input to the function computing the loss. Therefore, you don't need `a3`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebb694a3-65f4-4baf-99ce-e75b7221f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1afa254a-24d9-491d-8b8b-a4c87a97ea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72161, 10]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[5,10]\n",
    "[72161,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab6b0572-1acc-4e20-9244-d943a51b1f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 (linear output): Tensor(\"Add_4:0\", shape=(800, 1), dtype=float32)\n",
      "A3 (sigmoid output): Tensor(\"Sigmoid_3:0\", shape=(800, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset, of shape (num_examples, input size)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit before activation\n",
    "    A3 -- the output after applying sigmoid (for binary classification)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    # Convert X to a TensorFlow tensor (if it's not already a tensor)\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)\n",
    "    Z1 = tf.add(tf.matmul(X, W1), b1)  # Linear transformation\n",
    "    A1 = tf.nn.relu(Z1)  # ReLU activation\n",
    "    Z2 = tf.add(tf.matmul(A1, W2), b2)  # Linear transformation\n",
    "    A2 = tf.nn.relu(Z2)  # ReLU activation\n",
    "    Z3 = tf.add(tf.matmul(A2, W3), b3)  # Linear transformation (output layer)\n",
    "    A3 = tf.sigmoid(Z3)  # Sigmoid activation for binary classification\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3, A3  # Return both Z3 (linear output) and A3 (sigmoid output)\n",
    "\n",
    "\n",
    "def initialize_parameters(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Initializes parameters for a 3-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- input size (number of features)\n",
    "    n_y -- output size (number of outputs)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dictionary containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    # Initialize the weights and biases\n",
    "    W1 = tf.Variable(tf.keras.initializers.GlorotUniform()(shape=[n_x, 5]), name=\"W1\")  # [n_x, 5]\n",
    "    b1 = tf.Variable(tf.zeros_initializer()(shape=[1, 5]), name=\"b1\")  # [1, 5]\n",
    "    W2 = tf.Variable(tf.keras.initializers.GlorotUniform()(shape=[5, 10]), name=\"W2\")  # [5, 10]\n",
    "    b2 = tf.Variable(tf.zeros_initializer()(shape=[1, 10]), name=\"b2\")  # [1, 10]\n",
    "    W3 = tf.Variable(tf.keras.initializers.GlorotUniform()(shape=[10, n_y]), name=\"W3\")  # [10, n_y]\n",
    "    b3 = tf.Variable(tf.zeros_initializer()(shape=[1, n_y]), name=\"b3\")  # [1, n_y]\n",
    "\n",
    "    # Store the parameters in a dictionary\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\": W3, \"b3\": b3}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "\n",
    "# Example usage with your dataset\n",
    "\n",
    "# Assume X_train is your input dataset of shape (num_examples, num_features)\n",
    "# Assume y_train is your target output of shape (num_examples, 1)\n",
    "\n",
    "# Set the number of features (input size) and output size\n",
    "n_x = X_train.shape[1]  # 14 features in your dataset\n",
    "n_y = 1  # Binary classification output (0 or 1)\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = initialize_parameters(n_x, n_y)\n",
    "\n",
    "# Forward propagation\n",
    "Z3, A3 = forward_propagation(X_train, parameters)\n",
    "\n",
    "# Print the output\n",
    "print(\"Z3 (linear output):\", Z3)\n",
    "print(\"A3 (sigmoid output):\", A3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b19008-a7ad-43b4-a0c9-a1ffcec931a8",
   "metadata": {},
   "source": [
    "### **2.4 Compute cost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed098db-354f-4c09-b858-e0b0c6028f51",
   "metadata": {},
   "source": [
    "As seen before, it is very easy to compute the cost:\n",
    "\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=..., labels=...))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d94237-8344-4600-a4f3-16127ecb8cb4",
   "metadata": {},
   "source": [
    "#### **Question 8.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355481b-bafb-4dcb-b309-d6c9074a2788",
   "metadata": {},
   "source": [
    "Implement the cost function below.\n",
    "\n",
    "`tf.reduce_mean` basically does the mean operation over individual losses of examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8951569b-a83d-4f47-ab9e-33d0184870eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GRADED FUNCTION: compute_cost\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost for the binary classification model\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 1)\n",
    "    Y -- \"true\" labels vector, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshaping Z3 and Y to ensure correct dimensionality for tf.nn.sigmoid_cross_entropy_with_logits\n",
    "    logits = tf.reshape(Z3, (-1, 1))  # Ensure logits have shape [num_examples, 1]\n",
    "    labels = tf.reshape(Y, (-1, 1))   # Ensure labels have shape [num_examples, 1]\n",
    "    \n",
    "    # Compute cost using sigmoid cross entropy\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5b1f4-26c0-4416-9a64-6087236fca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(10, 1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d84b25c-c562-4c83-adf7-6df6e5707ff2",
   "metadata": {},
   "source": [
    "**cost**\tTensor(\"Mean:0\", shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a62aa9-3c9a-409e-acd9-5f69e3e0b9d3",
   "metadata": {},
   "source": [
    "### **2.5 Calculating Accuracy**\n",
    "\n",
    "For a classification problem, accuracy of a model is the number of correctly classified examples divided by number of total examples. i.e.\n",
    "\n",
    "```python\n",
    "accuracy = TP + TN / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161062e-211d-43c0-bdd5-03f115930fe1",
   "metadata": {},
   "source": [
    "Where  \n",
    "**TP** is number of true positives,  \n",
    "**TN** is the number of true negatives,  \n",
    "**N** is the number of all examples in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "417334b2-c3e9-4dab-972d-7d51873a63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(z, y):\n",
    "    z_array = np.array(z).T [1,3,4,5,6] \n",
    "    y_array = np.array(y).T\n",
    "    yhat_labels = (z_array > 0.5).astype(np.int)\n",
    "    correct_labels = np.sum(y_array == yhat_labels)\n",
    "    accuracy = correct_labels/y_array.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23a3e-8f19-4bc2-8626-bc292d9c7838",
   "metadata": {},
   "source": [
    "### **2.6 Backward propagation & parameter updates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a4026-a6f9-4af9-83da-0ee2490f6272",
   "metadata": {},
   "source": [
    "This is where you become grateful to programming frameworks. All the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.\n",
    "\n",
    "After you compute the cost function. You will create an \"optimizer\" object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.\n",
    "\n",
    "For instance, for gradient descent the optimizer would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4219eed-fd02-4b66-864f-ac7b75725cd6",
   "metadata": {},
   "source": [
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395a3be-ebbe-480e-bd28-873a59595c72",
   "metadata": {},
   "source": [
    "To make the optimization you would do:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef68e83-ca03-492a-8172-b52ad55a24f0",
   "metadata": {},
   "source": [
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: X, Y: Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878e7fa-3146-4fdc-8685-6b5355b89f9c",
   "metadata": {},
   "source": [
    "This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74174982-6603-4876-a063-a5a91caac397",
   "metadata": {},
   "source": [
    "### **2.7 Building the Final Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e35ce-ce43-458c-9fac-a84214e2a8be",
   "metadata": {},
   "source": [
    "#### **Question 9.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fcdc6-1958-43e9-83eb-85a9df2d399f",
   "metadata": {},
   "source": [
    "Implementation of Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8cbebed2-43e9-4873-9fb0-3394877aaf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have initialized and preprocessed your data (X_train_final, Y_train_final, X_test_final, Y_test_final)\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 500, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network for binary classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    train_acc = []                                    # To keep track of the training accuracy\n",
    "    test_acc = []                                     # To keep track of the test accuracy\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use GradientDescentOptimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            seed = seed + 1\n",
    "\n",
    "            # Run optimizer and compute cost\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "            \n",
    "            epoch_cost = c                # Defines a cost related to an epoch\n",
    "            \n",
    "            # Compute training accuracy\n",
    "            epoch_train_Z = sess.run(Z3, feed_dict={X: X_train})\n",
    "            epoch_train_accuracy = calculate_accuracy(epoch_train_Z, Y_train)\n",
    "            \n",
    "            # Compute test accuracy\n",
    "            epoch_test_Z = sess.run(Z3, feed_dict={X: X_test})\n",
    "            epoch_test_accuracy = calculate_accuracy(epoch_test_Z, Y_test)\n",
    "            \n",
    "            # Print the cost and accuracies every 100 epochs\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print(\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                train_acc.append(epoch_train_accuracy)\n",
    "                test_acc.append(epoch_test_accuracy)\n",
    "                \n",
    "        # Plot the cost vs. iterations graph\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot train vs. test accuracy over training epochs\n",
    "        plt.figure(figsize=(13,7))\n",
    "        plt.plot(np.squeeze(train_acc), color=\"red\", label=\"Train Accuracy\")\n",
    "        plt.plot(np.squeeze(test_acc), color=\"blue\", label=\"Test Accuracy\")\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Training Accuracy (Red) vs. Test Accuracy (Blue) Trend\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the parameters\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"Parameters have been trained!\")\n",
    "\n",
    "        # Accuracy on final train/test set\n",
    "        train_Z = sess.run(Z3, feed_dict={X: X_train})\n",
    "        train_accuracy = calculate_accuracy(train_Z, Y_train)\n",
    "        test_Z = sess.run(Z3, feed_dict={X: X_test})\n",
    "        test_accuracy = calculate_accuracy(test_Z, Y_test)\n",
    "\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2f6a001-5378-4546-b5a1-721822597026",
   "metadata": {},
   "source": [
    "parameters = model(x_train_final, y_train_final, x_test_final, y_test_final)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca40183b-cfee-4581-ac49-8d99cd39d755",
   "metadata": {},
   "source": [
    "Cost after epoch 0: 17.964821\n",
    "Cost after epoch 100: 1.002736\n",
    "Cost after epoch 200: 0.986673\n",
    "Cost after epoch 300: 0.971593\n",
    "Cost after epoch 400: 0.957571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0ad755d-cff1-4957-829d-3cc165ffd4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(r\"C:\\Users\\jorda\\Downloads\\code_1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c243c090-bb6e-4a0b-a8d3-28aa878be895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(r\"C:\\Users\\jorda\\Downloads\\code_2.png\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47908bab-6a98-46b1-847a-e219b5a294e2",
   "metadata": {},
   "source": [
    "Parameters have been trained!\n",
    "Train Accuracy: 0.9305164839733374\n",
    "Test Accuracy: 0.930510518001164"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
